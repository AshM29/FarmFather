{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10121848,"sourceType":"datasetVersion","datasetId":6245743}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-12-06T19:55:46.320722Z\",\"iopub.execute_input\":\"2024-12-06T19:55:46.321469Z\",\"iopub.status.idle\":\"2024-12-06T19:56:02.734088Z\",\"shell.execute_reply.started\":\"2024-12-06T19:55:46.321433Z\",\"shell.execute_reply\":\"2024-12-06T19:56:02.733053Z\"}}\nimport plotly.offline as pyo\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom wordcloud import WordCloud, STOPWORDS\nfrom PIL import Image\n\nimport plotly.graph_objs as go\nimport pandas as pd\nimport numpy as np\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\npd.options.display.max_columns = None\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ndf = pd.read_csv('/kaggle/input/crop-rec/Crop_recommendation.csv')\ndf.head()\n\ndf.shape\ndf.info()\ndf.describe()\n\n#correln between the features of the dataset\n\nfig, ax = plt.subplots(1, 1, figsize=(15, 9))\nnumdf = df.drop('label',axis=1)\nsns.heatmap(numdf.corr(), annot=True)\nax.set(xlabel='features')\nax.set(ylabel='features')\n\nplt.title('Correlation between different features', fontsize = 20, c='black')\nplt.show()\n\n#we start building the model here\n\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.preprocessing import LabelEncoder\n\ntarget = ['label']\nfeatures = ['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']\n\nlabel_encoder = LabelEncoder()\nnumerical_target = label_encoder.fit_transform(df[target])\n\nprint(df[['label']])\nprint(numerical_target)\ndf['numerical_label']=numerical_target\n# Mapping back from numerical to original labels\ndecoded_labels = label_encoder.inverse_transform(numerical_target)\nprint(\"Decoded Labels:\", decoded_labels)\n\nX = df[features]\ny = df[['numerical_label']]\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=True)\n\nmodels = []\nmodels.append(('LogisticRegression', LogisticRegression(random_state=0)))\nmodels.append(('DecisionTreeClassifier', DecisionTreeClassifier(random_state=0)))\nmodels.append(('XGBClassifier', XGBClassifier(random_state=0)))\nmodels.append(('GradientBoostingClassifier', GradientBoostingClassifier(random_state=0)))\nmodels.append(('KNeighborsClassifier', KNeighborsClassifier()))\nmodels.append(('RandomForestClassifier', RandomForestClassifier(random_state=0)))\n\nmodel_name = []\naccuracy = []\n\nfor name, model in models: \n    model.fit(X_train,y_train)\n    y_pred=model.predict(X_test)\n    model_name.append(name)\n    accuracy.append(metrics.accuracy_score(y_test,y_pred))\n    print(name, metrics.accuracy_score(y_test,y_pred))\n\nplt.figure(figsize=(15,9))\nplt.title('Accuracy Comparison')\nplt.xlabel('Accuracy')\nplt.ylabel('Model')\nsns.barplot(x = accuracy, y = model_name)\nplt.show()\n\nmodel=RandomForestClassifier(random_state=0)\nmodel.fit(X_train,y_train)\ny_pred=model.predict(X_test)\n\nfrom sklearn import metrics\n\ncm = metrics.confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(15,15))\nsns.heatmap(cm, annot=True, fmt=\".0f\", linewidths=.5, square = True, cmap = 'Blues_r');\nplt.ylabel('Actual label');\nplt.xlabel('Predicted label');\nall_sample_title = 'Confusion Matrix - score:'+str(metrics.accuracy_score(y_test,y_pred))\nplt.title(all_sample_title, size = 15);\nplt.show()\nprint(metrics.classification_report(y_test,y_pred))\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-12-06T19:56:40.369411Z\",\"iopub.execute_input\":\"2024-12-06T19:56:40.369845Z\",\"iopub.status.idle\":\"2024-12-06T19:57:15.307363Z\",\"shell.execute_reply.started\":\"2024-12-06T19:56:40.369808Z\",\"shell.execute_reply\":\"2024-12-06T19:57:15.306203Z\"}}\nfinal_model = RandomForestClassifier(random_state=0)\nfinal_model.fit(X,y)\n\n# Function to get user input  \ndef get_user_input():  \n    print(\"Please enter the following environmental parameters:\")  \n    N = float(input(\"Nitrogen (N) content in soil (kg/ha): \"))  \n    P = float(input(\"Phosphorus (P) content in soil (kg/ha): \"))  \n    K = float(input(\"Potassium (K) content in soil (kg/ha): \"))  \n    temperature = float(input(\"Temperature (Â°C): \"))  \n    humidity = float(input(\"Humidity (%): \"))  \n    ph = float(input(\"pH level of the soil: \"))  \n    rainfall = float(input(\"Rainfall (mm): \"))  \n    return [N, P, K, temperature, humidity, ph, rainfall]  \n\n# Get user input  \nuser_input = get_user_input()  \n\n# Convert to DataFrame for model prediction  \nuser_input_df = pd.DataFrame([user_input], columns=features)  \n\n# Predict the crop  \npredicted_label_numeric = final_model.predict(user_input_df)  \npredicted_label = label_encoder.inverse_transform(predicted_label_numeric)  \n\n# Display the result  \nprint(f\"The recommended crop for the given conditions is: {predicted_label[0]}\")  ","metadata":{"_uuid":"4823a7e7-e773-4281-9949-2d56850b0d44","_cell_guid":"c248cce6-0130-4103-a37e-c029590e71c6","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}